---
lang: fr
lang-ref: ch.11-1
lecturer: Awni Hannun
title: Reconnaissance vocale et Graph Transformer Network I
authors: Cal Peyser, Kevin Chang
date: 14 Apr 2021
typora-root-url: 11-1
translation-date: 22 Jun 2021
translator: Loïck Bourdois
---


<!--
## Modern Speech Recognition

This section is a high level introduction to speech recognition and modern speech recognition specifically why it's become so good, but what are some of the problems still.

* Automatic speech recognition has greatly improved since 2012
    * Machine perforamnce can be as good or better than human level perfomance
* Speech recognition still struggles in
    * conversational speech
    * mutiple speakers
    * lots of background noise
    * the accent of the speakers
    * certain features not well represented in the training data
* Pre 2012 speech recogonition systems consisted of lots of many hand engineered components
    * larger dataset is not useful so datasets reamin small
    * combining modules only at inference time instead of learning them together allowed for errors to cascade
    * researchers hard to know how to improve complex systems

* Post 2012 speech recogonition systems improvements
    * replaced a lot of the traditional components
    * add more data
    * above two together work in a virtuous cycle
-->

## Reconnaissance de la parole moderne

Cette section est une introduction à la reconnaissance vocale moderne : pourquoi elle est devenue si bonne mais aussi quels sont les problèmes qui subsistent.

* La reconnaissance automatique de la parole s'est grandement améliorée depuis 2012
    * La performance de la machine peut être aussi bonne ou meilleure que la performance humaine.
* La reconnaissance vocale a encore des difficultés dans le cadre :
    * d'un discours conversationnel,
    * de plusieurs locuteurs,
    * de beaucoup de bruit de fond,
    * de l'accent des locuteurs,
    * de certaines caractéristiques ne sont pas bien représentées dans les données d'entraînement.
* Les systèmes de reconnaissance vocale d'avant 2012 étaient constitués d'un grand nombre de composants conçus à la main :
    * un grand ensemble de données n'est pas utile donc les jeux de données sont petits,
    * la combinaison des modules uniquement au moment de l'inférence (au lieu de les apprendre ensemble) a entraîné des erreurs en cascade,
    * les chercheurs ont du mal à savoir comment améliorer les systèmes complexes.

* Améliorations des systèmes de reconnaissance vocale après 2012 :
    * remplacement d'une grande partie des composants traditionnels,
    * ajout de plus de données,
    * les deux éléments ci-dessus fonctionnent ensemble dans un cycle vertueux.


<!--
## The CTC Loss

Given some input speech utterance $\mX$, which consists of $T$ frames of audio. We desire to produce a transcription $\mY$ and we'll think of our transcription as consisting of the letters of a sentence, so $y_1$ is the first letter $y_U$ is the last letter.

$$
\mX=[x_1,...,x_T],\ \mY=[y_1,...,y_U]
$$

Compute conditional probability(the score) to evaluate transcription, we want to maximize the probability.

$$\log{P(\mY \mid \mX;\theta)}$$
-->

## La perte *Connectionist Temporal Classification*

Étant donné un audio en entrée $\mX$ composé de $T$ trames d'audio, nous souhaitons produire une transcription $\mY$. Nous considérerons que notre transcription est constituée de lettres donc $y_1$ est la première lettre $y_U$ est la dernière lettre.

$$
\mX=[x_1,...,x_T],\ \mY=[y_1,...,y_U]
$$

Nous voulons maximiser la probabilité conditionnelle (le score) pour évaluer la transcription :

$$\log{P(\mY \mid \mX;\theta)}$$



<!--
### Example 1

$$
\mX=[x_1, x_2, x_3],\ \mY=[c,a,t]
$$

$\mX$ has three frames, $\mY$ has three letters, the number of inputs matches the number of outputs, it's easy to compute the probability by one to one mapping.

$$\log{P(c \mid x_1)} + \log{P(a \mid x_2)} + \log{P(t \mid x_3)}$$
-->

### Exemple 1

$$
\mX=[x_1, x_2, x_3],\ \mY=[c,a,t]
$$

$\mX$ a trois images, $\mY$ a trois lettres. Le nombre d'entrées correspond au nombre de sorties, c'est donc facile de calculer la probabilité par correspondance un à un.

$$\log{P(c \mid x_1)} + \log{P(a \mid x_2)} + \log{P(t \mid x_3)}$$


<!--
### Example 2

$$
\mX=[x_1, x_2, x_3, x_4],\ \mY=[c,a,t]
$$

* Alignment: three possible ways
    * $A_1$: $x_1\rightarrow c$, $x_2\rightarrow a$, $x_3\rightarrow t$, $x_4\rightarrow t$
    * $A_2$: $x_1\rightarrow c$, $x_2\rightarrow a$, $x_3\rightarrow a$, $x_4\rightarrow t$
    * $A_3$: $x_1\rightarrow c$, $x_2\rightarrow c$, $x_3\rightarrow a$, $x_4\rightarrow t$
    
* Which alignment should we use to compute the score?
    * All of them. We're going to try to increase the score of all alignments and then hope the model sorts things out internally. The model can decide to optimize these different alignments and weight them accordingly and learn which one is the best.
    
$$\log{P(\mY \mid \mX)}=\log{[P(A_1 \mid \mX)+P(A_2 \mid \mX)+P(A_3 \mid \mX)]}$$
    
**Reminder**: use actual-softsoftmax to sum log probabilities.

We want $\log{(P_1+P_2)}$ from $\log{P_1}$ and $\log{P_2}$

$$
\begin{aligned}
\text{actual-softmax}(\log{P_1}, \log{P_2}) 
&= \log{P_1}+\log{P_2} \\
&= \log{(e^{\log{P1}}+e^{\log{P2}})}
\end{aligned}
$$
-->

### Exemple 2

$$
\mX=[x_1, x_2, x_3, x_4],\mY=[c,a,t]
$$

* Alignement : trois possibilités
    * $A_1$: $x_1\rightarrow c$, $x_2\rightarrow a$, $x_3\rightarrow t$, $x_4\rightarrow t$
    * $A_2$: $x_1\rightarrow c$, $x_2\rightarrow a$, $x_3\rightarrow a$, $x_4\rightarrow t$
    * $A_3$: $x_1\rightarrow c$, $x_2\rightarrow c$, $x_3\rightarrow a$, $x_4\rightarrow t$
    
* Quel alignement devons-nous utiliser pour calculer le score ?
Tous. Nous allons essayer d'augmenter le score de tous les alignements et espérer que le modèle fera le tri en interne. Le modèle peut décider d'optimiser ces différents alignements, les pondérer en conséquence et apprendre lequel est le meilleur.
    
$$\log{P(\mY \mid \mX)}=\log{[P(A_1 \mid \mX)+P(A_2 \mid \mX)+P(A_3 \mid \mX)]}$$
    
**Rappel** : utilisez l'*actual-softsoftmax* pour additionner les probabilités logarithmiques.

Nous voulons $\log{(P_1+P_2)}$ from $\log{P_1}$ and $\log{P_2}$

$$
\begin{aligned}
\text{actual-softmax}(\log{P_1}, \log{P_2}) 
&= \log{P_1}+\log{P_2} \\
&= \log{(e^{\log{P1}}+e^{\log{P2}})}
\end{aligned}
$$

<!--
### Alignment graph

Alignment graph is a way to encode the set of possible alignments to an arbitrary length input.
    
<center>
<img src="{{site.baseurl}}/images/week11/11-1/figure1.png" style="zoom: 40%; background-color:#DCDCDC;"/><br>
<b>Figure 1:</b> Alignment graph<br>
<br>
</center>

This graph is sometimes called weighted finite state accepter(WFSA). The bold state marked 0 at the beginning is a start state, the concentric circle marked 3 is an accepting state. On each edge, there're a label and a weight on both sides of a slash. Any path in this graph is an encoding of an alignment.
-->    

### Graphe d'alignement

Le graphe d'alignement est un moyen de coder l'ensemble des alignements possibles sur une entrée de longueur arbitraire.
    
<center>
<img src="{{site.baseurl}}/images/week11/11-1/figure1.png" style="zoom: 40%; background-color:#DCDCDC;"/><br>
<b>Figure 1 :</b> Graphe d'alignement<br>
<br>
</center>

Ce graphe est parfois appelé « accepteur d'états finis pondérés » (ou WFSA pour *weighted finite state acceptor*). L'état gras $0$ au début est un état de départ, le cercle concentrique $3$ est un état d'acceptation. 
Sur chaque arête, il y a une étiquette et un poids de part et d'autre d'une barre oblique (tous les poids valant $0$ dans l'image ci-dessus). Tout chemin dans ce graphe est un encodage d'un alignement.


<!--
### Problem: too many alignments

There's a problem when using all of the alignments. The $\mX$ input audio can have lots of frames, in practice they can be as high as thousands.
 The $\mY$ transcription can have lots of letters, in practice it can be hundreds or more. This is an astronomically large number of alignments, so we can't compute indivual score and sum all of them.
-->

#### Problème : trop d'alignements

Il y a un problème lorsque l'on utilise tous les alignements. L'entrée audio $\mX$ peut avoir beaucoup de trames (en pratique elles peuvent être des milliers).
La transcription $\mY$ peut contenir beaucoup de lettres (en pratique des centaines ou plus). 
Il s'agit donc d'un nombre astronomique d'alignements, nous ne pouvons donc pas calculer un score individuel et tous les additionner.


<!--
### Solution: the forward algorithm(dynamic programming)

Define forward variable $\alpha_t^u$, the subscript $t$ is where we are in the input and the superscript $u$ is where we are in the output. This represents the score for all alignments of length $t$ which end in the output $y_u$.

Suppose $\mX=[x_1,x_2,x_3,x_4]$, $\mY=[c,a,t]$, the forward variable $\alpha_2^c$ represents the score of all possible alignments of length two up to the first two frames that ends in $c$ in the first output of the transcription. There's only one possible alignment for that $x_1\rightarrow c$, $x_2\rightarrow c$. This is simple to compute.

$$\alpha_2^c=\log{P(c \mid x_1)}+\log{P(c \mid x_2)}$$

Similarly, $\alpha_2^a$ has only one possibility.

$$\alpha_2^a=\log{P(c \mid x_1)}+\log{P(a \mid x_2)}$$

For $\alpha_3^a$, there are two possible alignments

* $A_1$: $x_1\rightarrow c$, $x_2\rightarrow c$, $x_3\rightarrow a$
* $A_2$: $x_1\rightarrow c$, $x_2\rightarrow a$, $x_3\rightarrow a$

$$
\alpha_3^a=\text{actual-softmax}[\log{P(A_1)}, \log{P(A_2)}] \\
\log{P(A_1)}=\log{P(c \mid x_1)}+\log{P(c \mid x_2)}+\log{P(a \mid x_3)} \\
\log{P(A_2)}=\log{P(c \mid x_1)}+\log{P(a \mid x_2)}+\log{P(a \mid x_3)}
$$

This is the naive approch to compute $\alpha_3^a$.

Using this forward variable, we seek to model the probablity distribution $P(\mY \mid \mX) = \sum_{a \in A} P(a)$, where $A$ is the set of all possible alignments from $\mY$ to $\mX$.  This decomposes as 

$$P(\mY \mid \mX) = \sum_{a \in A}  \prod_{t=1}^T P(a_t \mid \mX)$$

where $P(a_t \mid \mX)$ are the output logits of a system such as an RNN. That is, to compute the likelihood of the transcript $\mY$ we must marginalize over an intractably large number of alignments.  We may do this with a recursive decomposition of the forward variable.  The below presentation is inspired by https://distill.pub/2017/ctc/, which is an excellent introduction to the algorithm.

First, we permit an alignment to contain the empty output $\epsilon$ in order to account for the fact that audio sequences are longer than their corresponding transcripts.  We also collapse repetitions, so that $\{a, \epsilon, a, a, \epsilon, a\}$ corresponds to the sequence $aaa$.  We will also define $\alpha$ using an alternative transcript $Z$, which is equal to $\mY$ but is interspersed with $\epsilon$.  That is, $Z = \{\epsilon, y_1, \epsilon, y_2, ..., y_n, \epsilon \}$.

Now, suppose $y_i = y_{i+1}$, so that $Z$ contains a subsequence $y_i, \epsilon, y_{i+1}$, and suppose $y_{i+1}$ occurs at position $s$ in $Z$.  Then the alignment for $\alpha_{s}^t$ can be arrived at by one of two ways: either the prediction at time $t-1$ can be $y_{i+1}$ (in which case the repetition is collapesed) or else the prediction at time $t-1$ can be epsilon.  So, we may decompose:

$$\alpha_s^t = (\alpha_{s, t-1} + \alpha_{s-1, t-1}) P(z_s \mid \mX)$$

where the elements of the sum represent the two possible prefixes to the alignment.  If, on the other hand, we have $y_i \ne y_{i+1}$ then there is the additional third possiblity that the prediction at time $t-1$ is equal to $y_i$.  So, we have the decomposition

$$\alpha_s^t = (\alpha_{s, t-1} + \alpha_{s-1, t-1} + \alpha{s-2, t-1}) P(z_s \mid \mX)$$

By computing $\alpha_{\vert Z\vert}^{T}$, we may effectively marginalize over all possible alignments between the transcript $\mY$ and the audio $\mX$, allowing efficient training and inference.  This is called Connectionist Temporal Classification, or CTC.
-->


### Solution : l'algorithme *forward* (programmation dynamique)

Dans la variable *forward* $\alpha_t^u$, l'indice $t$ est l'endroit où nous sommes dans l'entrée et l'exposant $u$ est l'endroit où nous sommes dans la sortie. 
Elle représente le score pour tous les alignements de longueur $t$ qui se terminent dans la sortie $y_u$.

Supposons que $\mX=[x_1,x_2,x_3,x_4]$, $\mY=[c,a,t]$, la variable *forward* $\alpha_2^c$ représente le score de tous les alignements possibles de longueur deux jusqu'aux deux premières trames qui se termine par $c$ dans la première sortie de la transcription. 
Il n'y a qu'un seul alignement possible pour ce $x_1\rightarrow c$, $x_2\rightarrow c$. C'est donc simple à calculer :

$$\alpha_2^c=\log{P(c \mid x_1)}+\log{P(c \mid x_2)}$$.

De même, $\alpha_2^a$ n'a qu'une seule possibilité :

$$\alpha_2^a=\log{P(c \mid x_1)}+\log{P(a \mid x_2)}$$.

Pour $\alpha_3^a$, il y a deux alignements possibles :
* $A_1$: $x_1\rightarrow c$, $x_2\rightarrow c$, $x_3\rightarrow a$
* $A_2$: $x_1\rightarrow c$, $x_2\rightarrow a$, $x_3\rightarrow a$

$$
\alpha_3^a=\text{actual-softmax}[\log{P(A_1)}, \log{P(A_2)}] \\
\log{P(A_1)}=\log{P(c \mid x_1)}+\log{P(c \mid x_2)}+\log{P(a \mid x_3)} \\
\log{P(A_2)}=\log{P(c \mid x_1)}+\log{P(a \mid x_2)}+\log{P(a \mid x_3)}
$$

C'est l'approche naïve pour calculer $\alpha_3^a$.

En utilisant cette variable directe, nous cherchons à modéliser la distribution de probabilité $P(\mY \mid \mX) = \sum_{a \in A} P(a)$, où $A$ est l'ensemble de tous les alignements possibles de $\mY$ à $\mX$.  Ceci se décompose comme suit :

$$P(\mY \mid \mX) = \sum_{a \in A} \prod_{t=1}^T P(a_t \mid \mX)$$

où $P(a_t \mid \mX)$ sont les logits de sortie d'un système tel qu'un RNN.

En d'autres termes, pour calculer la vraisemblance de la transcription $\mY$, nous devons marginaliser sur un nombre irréductiblement grand d'alignements.  
Nous pouvons le faire avec une décomposition récursive de la variable directe.  
La présentation ci-dessous est inspirée d'un article de [distill.pub](https://distill.pub/2017/ctc/) qui est une excellente introduction à l'algorithme.


Tout d'abord, nous permettons à un alignement de contenir la sortie vide $\epsilon$ afin de tenir compte du fait que les séquences audio sont plus longues que leurs transcriptions correspondantes.  
Nous réduisons également les répétitions, de sorte que $\{a, \epsilon, a, a, \epsilon, a\}$ correspond à la séquence $aaa$.  
Nous allons également définir $\alpha$ en utilisant une transcription alternative $Z$, qui est égale à $\mY$ mais est entrecoupée de $\epsilon$.  
En d'autres termes, $Z = \{\epsilon, y_1, \epsilon, y_2, ..., y_n, \epsilon \}$.

Supposons maintenant que $y_i = y_{i+1}$, de sorte que $Z$ contient une sous-séquence $y_i, \epsilon, y_{i+1}$, et supposons que $y_{i+1}$ se trouve à la position $s$ dans $Z$.  
Alors l'alignement pour $\alpha_{s}^t$ peut être obtenu de deux manières : soit la prédiction au temps $t-1$ peut être $y_{i+1}$ (auquel cas la répétition est collapsée), soit la prédiction au temps $t-1$ peut être epsilon. On peut donc décomposer :

$$\alpha_s^t = (\alpha_{s, t-1} + \alpha_{s-1, t-1}) P(z_s \mid \mX)$$

où les éléments de la somme représentent les deux préfixes possibles de l'alignement.  Si, d'autre part, nous avons $y_i \ne y_{i+1}$ alors il y a la troisième possibilité supplémentaire que la prédiction au temps $t-1$ soit égale à $y_i$.  Ainsi, nous avons la décomposition

$$\alpha_s^t = (\alpha_{s, t-1} + \alpha_{s-1, t-1} + \alpha{s-2, t-1}) P(z_s \mid \mX)$$

En calculant $\alpha_{\vert Z\vert}^{T}$, nous pouvons effectivement marginaliser tous les alignements possibles entre la transcription $\mY$ et l'audio $\mX$, ce qui permet un apprentissage et une inférence efficaces.  C'est ce qu'on appelle la *Connectionist Temporal Classification* ou CTC.

