---
lang: fr
lang-ref: ch.11-2
lecturer: Awni Hannun
title: Reconnaissance vocale et Graph Transformer Network II
authors: Gyanesh Gupta, Abed Qaddoumi
date: 14th April 2021
typora-root-url: 11-2
translation-date: 22 Jun 2021
translator: Loïck Bourdois
---


<!--
## Inference Time

The inference of a transcription from a given audio signal can be formulated using 2 distributions:

* The acoustic model (audio to transcription), represented as $P(\mY \mid \mX)$
* The language model, $P(\mY)$

The final inference is obtained by taking sum of the log probabilities of the above two, i.e.

$$ \vect{\mY*} = \underset{\mY}{\operatorname{argmax}} \log P(\mY \mid \mX) + \log P(\mY) $$

We use the additional term to ensure the transcription is consistent with the rules of the language. Else we may get grammatically wrong transcription.
-->

## Temps d'inférence

L'inférence pour obtenir la transcription d'un signal audio donné peut être formulée en utilisant deux distributions :
* Le modèle acoustique (de l'audio à la transcription), représenté par $P(\mY \mid \mX)$.
* Le modèle linguistique, représenté par $P(\mY)$.

L'inférence finale est obtenue en prenant la somme des probabilités logarithmiques de ces deux modèles, c'est-à-dire :

$$ \vect{\mY*} = \underset{\mY}{\operatorname{argmax}} \log P(\mY \mid \mX) + \log P(\mY) $$

Nous utilisons le terme supplémentaire pour nous assurer que la transcription est conforme aux règles de la langue. Sinon, nous risquons d'obtenir une transcription grammaticalement incorrecte.


<!--
## Beam Search

While returning an output sequence, we can follow the greedy approach, where we take the maximum value of $P(\vy_{t} \mid \vy_{t-1}...\vy_{1})$

However, we can end up missing out a good sequence, which may not have the maximum value of $P(\vy_{t} \mid ...)$, as illustrated by the example below.

<center>
<img src="{{site.baseurl}}/images/week11/11-2/greedy.png" style="background-color:#DCDCDC; ; filter: invert(100%)"/><br>
<b>Figure 1:</b> Greedy Approach : Less Optimal Solution<br>
<br>
</center>

To remedy this, we employ beam search. Essentially, we consider maximum $k$ tokens in terms of probability at each step $t$ of the sequence. For each of these n-grams, we proceed further and find out the maximum. 

The illustration below shows how Beam Search can lead to a better sequence.

<center>
<img src="{{site.baseurl}}/images/week11/11-2/bs3.png" style="background-color:#DCDCDC; ; filter: invert(100%)"/><br>
<b>Figure 2:</b> Beam Search : Stage 1 <br>
<br>
</center>

<center>
<img src="{{site.baseurl}}/images/week11/11-2/bs1.png" style="background-color:#DCDCDC; ; filter: invert(100%)"/><br>
<b>Figure 3:</b> Beam Search : Stage 2<br>
<br>
</center>

<center>
<img src="{{site.baseurl}}/images/week11/11-2/bs2.png" style="background-color:#DCDCDC; ; filter: invert(100%)"/><br>
<b>Figure 4:</b> Beam Search : Stage 3<br>
<br>
</center>
-->

## Recherche en faisceau

Lors de la génération d'une séquence, nous pouvons suivre l'approche gloutonne où nous prenons la valeur maximale de $P(\vy_{t} \mid \vy_{t-1}...\vy_{1})$.

Cependant, nous pouvons manquer une bonne séquence qui peut ne pas avoir la valeur maximale de $P(\vy_{t} \mid ...)$ comme l'illustre l'exemple ci-dessous.


<center>
<img src="{{site.baseurl}}/images/week11/11-2/greedy.png" style="background-color:#DCDCDC; ; filter: invert(100%)"/><br>
<b>Figure 1 :</b> Approche gloutonne (en bleue) : une solution moins optimale<br>
<br>
</center>

Pour remédier à cela, nous employons la recherche en faisceau. Grossièrement, nous considérons les jetons maximum $k$ en termes de probabilité à chaque étape $t$ de la séquence. 
Pour chacun de ces n-grammes, nous poursuivons la recherche et trouvons le maximum. 

L'illustration ci-dessous montre comment la recherche en faisceau peut conduire à une meilleure séquence.

<center>
<img src="{{site.baseurl}}/images/week11/11-2/bs3.png" style="background-color:#DCDCDC; ; filter: invert(100%)"/><br>
<b>Figure 2 :</b> Recherche en faisceau : étape 1 <br>
<br>
</center>

<center>
<img src="{{site.baseurl}}/images/week11/11-2/bs1.png" style="background-color:#DCDCDC; ; filter: invert(100%)"/><br>
<b>Figure 3 :</b> Recherche en faisceau : étape 2<br>
<br>
</center>

<center>
<img src="{{site.baseurl}}/images/week11/11-2/bs2.png" style="background-color:#DCDCDC; ; filter: invert(100%)"/><br>
<b>Figure 4 :</b> Recherche en faisceau : étape 3<br>
<br>
</center>



<!--
## Graph Transformer Networks

We have previously seen Weighted Finite State Automata (WFSA) being used to represent the alignment graphs, as shown before.


Graph Transformer Networks (GTNs) are basically WSFA with automatic differentiation.

Lets look at key differences between Neural Networks (NNs) and GTNs



|  | NN | GTN |
| -------- | -------- | -------- |
| Core Data Structure     | Tensor     | Graph/WFSA     |
|     | Matrix Multiplcation     | Compose     |
| Core Operations  | Reduction operations (Sum, Product)| Shortest Distance (Viterbi,Forward) |
| | Negate, Add, Subtract, ...     | Closure, Union, Concatenate, ...    |
-->

## Graph Transformer Networks

Nous avons vu précédemment le *Weighted Finite State Acceptor* (WFSA)  pour représenter les alginements dans un graphe.


Les *Graph Transformer Networks* (GTNs) sont essentiellement des WSFAs avec une différenciation automatique.

Examinons les principales différences entre les réseaux de neurones (NNs) et les GTNs.

|  | NN | GTN
| -------- | -------- | -------- |
| Structure de données de base |  Tenseur | Graphe/WFSA |
| | Multiplémentation matricielle | Compose |
| Opérations de base | Opérations de réduction (Somme, Produit)| Distance la plus courte (Viterbi, *Forward*) |
| | Négation, Addition, Soustraction, ...     | Fermeture, Union, Concaténation, ...    |


<!--
## Why Differentiable WSFAs?

* Encode Priors: easy to encode priors into a graph
* End-to-end: Bridge the training and test process 
* Facilitate research: When we separate the data from the code it makes it easier to explore different ideas. In our case graph is the data and the code is operations allows us to explore different ideas by changing the graph.
-->

## Pourquoi des WSFAs différentiables ?

* Encodage des a priori : facile d'encoder les a priori dans un graphe.
* Bout en bout : permet de faire le pont entre le processus d'entrâinement et de test 
* Faciliter la recherche académique : lorsque nous séparons les données du code, il est plus facile d'explorer différentes idées. Dans notre cas, le graphe est la donnée et le code est l'opération, ce qui nous permet d'explorer différentes idées en modifiant le graphe.


<!--
## Sequence Criteria with WFSAs

It turns out that lots of the sequence criteria like connection temporal classification (CTC) can be specified as the difference between two forward scores.

* Graphs A: function of input \mX (speech) and target "output" \mY (transription).
* Graph Z: function of input \mX, which servers as normalization.
* Loss: $\log P(\mY \mid \mX) = \text{forwardScore}(A_{\mX,\mY}) - \text{forwardScore}(Z_{\mX})$

Other common loss functions in ASR:

* Automatic Segmentations Criterion (ASG)
* Connectionist TEmporal  Classification (CTC)
* Lattice Free MMI (LF-MMI)
-->

## Critères de séquence avec WFSAs

Il s'avère que de nombreux critères de séquence peuvent être spécifiés comme la différence entre deux scores *forward*.

* Graphes A : fonction de l'entrée $\mX$ (parole) et de la sortie cible $\mY$ (transcription).
* Graphe Z : fonction de l'entrée $\mX$, qui sert de normalisation.
* Perte : $\log P(\mY \mid \mX) = \text{forwardScore}(A_{\mX,\mY}) - \text{forwardScore}(Z_{\mX})$.

Des fonctions de perte courantes en reconnaissance automatique de la parole :

* Critère de segmentation automatique (ASG pour *Automatic Segmentations Criterion*)
* Classification Temporale Connectioniste (CTC pour *Connectionist Temporal  Classification*)
* MMI sans treillis (LF-MMI pour *Lattice Free Maximum Mutual Information*)

<!--
### Lines of code for CTC: Custom vs GTN

|            | GTN   |
| ---------- | ----- |
| Warp-CTC   | 9,742 |
| wav2letter | 2,859 |
| PyTorch    | 1,161 |
| GTN        | 30*   |

\*Same graph code works for decoding.
-->

### Nombre de lignes de code pour implémenter la CTC

|            | Lignes |
| ---------- | ----- |
| Warp-CTC | 9,742 |
| wav2letter | 2,859 |
| PyTorch | 1,161 |
| gtn | 30* |

\*Le même code fonctionne pour le décodage.

<!--
## Different Types of WFS

### Weighted Finite-State Acceptor (WFSA)

The bold circle is the starting state and the accepting state is the one with concentric circles. 

#### Example

A simple WFSA which recognizes aa or ab
* The score of **aa** is 0 + 2 = 2
* The score of **ba** is 1 + 2 = 3


<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure5.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 5:</b> Three Nodes Weighted Finite-State Acceptor (WFSA)<br>
<br>
</center>
-->

## Différents types d'états finis pondérés

### Accepteur d'états finis pondérés (WFSA pour *Weighted Finite-State Acceptor*)

Le cercle en gras est l'état de départ et l'état d'acceptation est celui avec les cercles concentriques. 

#### Exemple

Un WFSA simple reconnaît les séquences **aa** et **ab** avec comme score : 
* Le score de **aa** est $0 + 2 = 2$
* Le score de **ba** est $1 + 2 = 3$

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure5.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 5 :</b> Accepteur d'états finis pondérés (WFSA) à trois nœuds<br>
<br>
</center>

<!--
### Weighted Finite-State Transducer (WFST)

These graphs are called transducers because they map input sequences to output sequences. 

#### Example

A simple WFST that recognizes ab to xz and bb to yz.
* The score of **ab $\to$ xz** is 1.1 + 3.3 = 4.4
* The score of **bb $\to$ yz** is 2.0 + 3.3 = 5.3


<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure6.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 6:</b> Three Nodes Weighted Finite-State Transducer (WFST) <br>
<br>
</center>
-->

### Transducteur à états finis pondérés (WFST pour *Weighted Finite-State Transducer*)

Ces graphes sont appelés transducteurs car ils transforment des séquences d'entrée en séquences de sortie. 

#### Exemple

Un WFST simple reconnaît ab à xz et bb à yz  avec comme score :
* Le score de **ab $\to$ xz** est $1,1 + 3,3 = 4,4$
* Le score de **bb $\to$ yz** est de $2,0 + 3,3 = 5,3$

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure6.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 6 :</b> Transducteur d'états finis pondérés (WFST) à trois nœuds <br>
<br>
</center>


<!--
### More WFSAs and WFSTs

* Cycles and self-loops are allowed
* Multiple start and accept nodes are allowed
* $\epsilon$ "nothing" transitions are allowed in WFSAs and WFSTs.
-->
### Plus de WFSAs et WFSTs

* Les cycles et les boucles sont autorisés.
* Les nœuds de départ et d'arrivée multiples sont autorisés.
* Les transitions de type $\epsilon$ (c'est-à-dire faisant rien) sont autorisées dans les WFSAs et WFSTs.


<!--
## Operations:

### Unions

The union accepts a sequence if it is accepted by any of the input graphs. 

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure7.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 7:</b> Union Operation Between Three Graphs <br>
<br>
</center>
-->

## Les différentes opérations

### Union

L'union accepte une séquence si elle est acceptée par l'un des graphes d'entrée. 

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure7.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 7 :</b> Opération d'union entre trois graphes<br>
<br>
</center>


<!--
### Kleene Closure

Accepts any accepted sequence by input graph repeated 0 or more times.

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure8.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 8:</b> Kleene Closure Operation <br>
<br>
</center>
-->

### Etoile de Kleene

Accepte toute séquence acceptée par le graphe d'entrée répétée 0 fois ou plus.

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure8.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 8 :</b> Opération de l'étoile de Kleene <br>
<br>
</center>

<!--
### Intersect

Similar to matrix multiplication or convolution. This operation is probably the most important in GTNs. 
1. Any path that is accepted by both WFSAs is accepted by the product of the intersection.
2. The score of the instersected path is the sum of the scores of the paths in the input graphs. 

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure9.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 9:</b> Intersection Operation Between Two Graphs <br>
<br>
</center>
-->

### Intersection

Similaire à la multiplication matricielle ou à la convolution. Cette opération est probablement la plus importante dans les GTNs. 
1. Tout chemin qui est accepté par les deux WFSA est accepté par le produit de l'intersection.
2. Le score du chemin instersecté est la somme des scores des chemins des graphes d'entrée. 

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure9.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 9 :</b> Opération d'intersection entre deux graphes <br>
<br>
</center>


<!--
### Compose

It is basically the same thing as intersection but for transducers instead of acceptors. 

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure10.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 10:</b> Compose Operation Between Two Graphs <br>
<br>
</center>

The main thing about composition is that it let's map from different domains. For example, if we have a graph that maps from letters to words and another graph that maps from words to sentences. When we compose these two graphs we will map from letters to sentences. 
-->

### Composition

C'est essentiellement la même chose que l'intersection mais pour les transducteurs au lieu des accepteurs. 

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure10.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 10 :</b> Opération de composition entre deux graphes <br>
<br>
</center>

La principale chose à propos de la composition est qu'elle permet de faire des correspondances à partir de différents domaines. Par exemple, si nous avons un graphe qui fait correspondre des lettres aux mots et un autre graphe qui fait correspondre des mots aux phrases, alors lorsque nous composons ces deux graphes nous faisons correspondre des lettres aux phrases. 



<!--
### Forward Score

Assumes the graph is **DAG** and an efficient dynamic programming algorithm.

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure11.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 11:</b> Forward Score is the Softmax of the Paths <br>
<br>
</center>

The graphs accepts three paths: 
* **aca** with score = 1.1 + 1.4 + 2.1
* **ba** with score = 3.2 + 2.1
* **ca** with score 1.4 + 2.1

ForwardScore(g) is the actual-softmax of the paths.
-->

### Score *forward*

Supposons que le graphe est **DAG** (c'est-à-dire dirigé et sans boucles) et avons un algorithme de programmation dynamique efficace.

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure11.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
    <b>Figure 11 :</b> Le score <i>forward</i> est la SoftMax des chemins <br>
<br>
</center>

Les graphes acceptent trois chemins : 
* **aca** avec comme score $1,1 + 1,4 + 2,1$
* **ba** avec comme score $3,2 + 2,1$
* **ca** avec  commescore $1,4 + 2,1$

Le *ForwardScore(g)* est la SoftMax réelle des chemins.


<!--
## Sequence Criteria with WFSTs 

### Target graph Y:

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure12.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 12:</b> Target Graph \mY <br>
<br>
</center>
-->
### Séquence de critères avec WFSTs 

### Graphe cible $\mY$

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure12.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 12 :</b> Graphe cible Y <br>
<br>
</center>

<!--
### Emissions graph E:

Think of it between two nodes we have logits.

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure13.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 13:</b> Emission Graph E <br>
<br>
</center>
-->

### Graphe des émissions E

Entre deux nœuds nous avons des logits.

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure13.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 13 :</b> Graphe des émissions E <br>
<br>
</center>

<!--
### Target contrained graph A by intersection(Y, E):

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure14.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 14:</b> Target Constrained Graph <br>
<br>
</center>
-->

### Graphe contraint par la cible A par intersection ($\mY$, E)

<center>
<img src="{{site.baseurl}}/images/week11/11-2/figure14.png" style="background-color:#DCDCDC; filter: invert(100%)"/><br>
<b>Figure 14 :</b> Graphe contraint par la cible <br>
<br>
</center>

<!--
### Loss

$$
\ell = - (\text{forwardScore}(A) - \text{forwardScore}(E))
$$

This is not CTC but approaches CTC. 
-->

### Perte

$$
\ell = - (\text{forwardScore}(A) - \text{forwardScore}(E))
$$

Ce n'est pas la CTC mais ça s'en approche. 

<!--
## Code examples:

### Make the target graph

Similar to figure 8.

~~~python
import gtn

# Make the graph 
target = gtn.Graph(calc_grad=False)
# Add nodes:
target.add_node(start=True)
target.add_node()
target.add_node(accept=True)
# Add arcs:
target.add_arc(src_node=0, dst_node=1, label=0)
target.add_arc(src_node=1, dst_node=1, label=0)
target.add_arc(src_node=1, dst_node=2, label=1)
target.add_arc(src_node=2, dst_node=2, label=1)
# Draw the graph
label_map = {0: 'a', 1: 'b'}
gtn.draw(target, "target.pdf", label_map)
~~~
-->

### Exemples de code

### Créer le graphe cible

Similaire à la figure 8.

~~~python
import gtn

# On crée le graphe
target = gtn.Graph(calc_grad=False)
# Ajouts des noeuds
target.add_node(start=True)
target.add_node()
target.add_node(accept=True)
# Ajouts des arcs
target.add_arc(src_node=0, dst_node=1, label=0)
target.add_arc(src_node=1, dst_node=1, label=0)
target.add_arc(src_node=1, dst_node=2, label=1)
target.add_arc(src_node=2, dst_node=2, label=1)
# On dessine le graphe
label_map = {0: 'a', 1: 'b'}
gtn.draw(target, "target.pdf", label_map)
~~~

<!--
### Make the emissions graph 

Similar to figure 9.

~~~python
import gtn

# Emissions array (logits)
emissions_array = np.random.randn(4, 3)
# Make the graph 
emissions = gtn.linear_graph(4, 3, calc_grad=True)
# Set the weights 
emissions.set_weights()
~~~
-->

### Faire le graphe des émissions 

Similaire à la figure 9.

~~~python
import gtn

# Tableau des émissions (logits)
emissions_array = np.random.randn(4, 3)
# Créer le graphe 
emissions = gtn.linear_graph(4, 3, calc_grad=True)
# Définir les poids
emissions.set_weights()
~~~

<!--
## ASG in GTN 

### Steps

1. Compute the graphs 
2. Compute the loss
3. Automatic gradients 

~~~python
from gtn import *

def ASG(emissions, target):
    # Step 1
    # Compute constrained and normalization graphs:
    A = intersect(target, emissions)
    Z = emissions

    # Step 2: 
    # Forward both.graphs: 
    A_score = forward(A)
    Z_score = forward(Z)
    
    # Compute loss:
    loss = negate(subtract(A_score, Z_score))
    
    # Step 3: 
    # Clear previous gradients:
    emissions.zero_grad()
    
    # Compute gradients:
    backward(loss, retain_graph=False)
    return loss.item(), emissions.grad()
~~~
-->

## L'ASG dans GTN 

### Étapes

1. Calculer les graphes 
2. Calculer la perte
3. Gradients automatiques 

~~~python
from gtn import *

def ASG(emissions, target):
    # Etape 1
    # Calculs des graphes :
    A = intersect(target, emissions)
    Z = emissions

    # Etape 2
    # Forward both.graphs : 
    A_score = forward(A)
    Z_score = forward(Z)
    
    # Compute loss:
    loss = negate(subtract(A_score, Z_score))
    
    # Etape 3 
    # Nettoyage des gradients précédents
    emissions.zero_grad()
    
    # Calcul des gradients
    backward(loss, retain_graph=False)
    return loss.item(), emissions.grad()
~~~


<!--
## CDC in GTN 

~~~python
from gtn import *

def CTC(emissions, "target"):
    ...
~~~

The only difference is the target which makes it very easy to try different algorithms and the GTN framework is supposed to be similar to PyTorch with different data structure and operations. 
-->

## CTC dans GTN 

~~~python
from gtn import *

def CTC(émissions, "target") :
    # Etape 1
    # Calculs des graphes :
    A = intersect(target, emissions)
    Z = emissions

    # Etape 2
    # Forward both.graphs : 
    A_score = forward(A)
    Z_score = forward(Z)
    
    # Compute loss:
    loss = negate(subtract(A_score, Z_score))
    
    # Etape 3 
    # Nettoyage des gradients précédents
    emissions.zero_grad()
    
    # Calcul des gradients
    backward(loss, retain_graph=False)
    return loss.item(), emissions.grad()
~~~

La seule différence est la cible ici. Elle rend très facile l'essai de différents algorithmes et gtn est censé être similaire à PyTorch avec une structure de données et des opérations différentes. 


<!--
## Futher readings: 

* **CTC**
   * [Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks, Graves, et al. 2006, ICML](https://www.cs.toronto.edu/~graves/icml_2006.pdf)
   * [Sequence Modeling with CTC, Hannun. 2017, Distill](https://distill.pub/2017/ctc/)
* **GTN**
   * [Gradient-based learning applied to document recognition, LeCun, et al. 1998, Proc. IEEE](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)
   * [Global Training of Document Processing Systems using Graph Transformer Networks, Bottou, et al. 1997, CVPR](http://yann.lecun.com/exdb/publis/pdf/bottou-lecun-bengio-97.pdf)
   * [More references](https://leon.bottou.org/talks/gtn)
* **Modern GTNs**
   * [Code](https://github.com/facebookresearch/gtn), `pip install gtn`
   * [Differentiable Weighted Finite-State Transducers, Hannun, et al. 2020](https://arxiv.org/abs/2010.01003)
-->

## Lectures supplémentaires 

* Sur la **CTC** :
   * [Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks, Graves, et al. 2006, ICML](https://www.cs.toronto.edu/~graves/icml_2006.pdf)
   * [Sequence Modeling with CTC, Hannun. 2017, Distill](https://distill.pub/2017/ctc/)
* Sur le **GTN** :
   * [Gradient-based learning applied to document recognition, LeCun, et al. 1998, Proc. IEEE](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)
   * [Global Training of Document Processing Systems using Graph Transformer Networks, Bottou, et al. 1997, CVPR](http://yann.lecun.com/exdb/publis/pdf/bottou-lecun-bengio-97.pdf)
   * [More references](https://leon.bottou.org/talks/gtn)
* Sur les **GTNs modernes** :
   * [Code](https://github.com/facebookresearch/gtn), `pip install gtn`
   * [Differentiable Weighted Finite-State Transducers, Hannun, et al. 2020](https://arxiv.org/abs/2010.01003)
