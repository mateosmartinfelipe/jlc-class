---
lang: fr
lang-ref: ch.03
title: Semaine 3
translation-date: 19 June 2021
translator: Loïck Bourdois
---


<!--
## Lecture

Parts can be found [here](https://atcold.github.io/pytorch-Deep-Learning/en/week03/03-1/) and part [here](https://atcold.github.io/pytorch-Deep-Learning/en/week06/06-2/).
-->
## Cours magistral
Les différentes parties peuvent être trouvées [ici](https://atcold.github.io/pytorch-Deep-Learning/fr/week03/03-1/) et [ici](https://atcold.github.io/pytorch-Deep-Learning/fr/week06/06-2/).


<!--
## Practicum
We introduced how to draw deep network schematics conveniently using diagrams.net. Then we showed the different effect of using only linear transformation, and the effect of combining linear and non-linear transformation together on spiral classification. Finally, we showed the mathematical principles underlying neural networks, including chain rule derivation, back propagation, and gradient descent.
-->
## Travaux dirigés
Nous présentons comment dessiner des schémas de réseaux profonds de manière pratique en utilisant **diagrams.net**. Nous montrons ensuite les différents effets de l'utilisation de la seule transformation linéaire, et l'effet de la combinaison de la transformation linéaire et non linéaire sur la classification en spirale. Enfin nous voyons les principes mathématiques qui sous-tendent les réseaux neuronaux, notamment le théorème de dérivation des fonctions composées, la rétropropagation et la descente de gradient.
