---
lang: fr
lang-ref: ch.07-3
title: Introduction aux auto-encodeurs
lecturer: Alfredo Canziani
authors: Vidit Bhargava, Monika Dagar
date: 18 March 2021
typora-root-url: 07-3
translation-date: 19 Aug 2021
translator: Loïck Bourdois
---

<!--
## Applications of Autoencoder

### DALL-E: Creating Images from Text

DALL-E (released by OpenAI) is a neural network based on the Transformers architecture, that creates images from text captions. 
It is a 12-billion parameter version of [GPT-3](https://arxiv.org/abs/2005.14165), trained on a dataset of text-image pairs.

<center>
<img src="{{site.baseurl}}/images/week07/07-3/DALL-E.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 1:</b> DALL-E: Input-Output
</center>

Go to the [website](https://openai.com/blog/dall-e/) and play with the captions! 
-->

## Applications de l'auto-encodeur

### DALL-E : Création d'images à partir de texte

DALL-E (publié par OpenAI) est un réseau neuronal basé sur l'architecture Transformer créant des images à partir de légendes de texte.
Il s'agit d'une version à $12$ milliards de paramètres de [GPT-3](https://arxiv.org/abs/2005.14165) entraînée sur un jeu de données de paires texte-image.  

<center>
<img src="{{site.baseurl}}/images/week07/07-3/DALL-E.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 1 :</b> DALL-E : entrée-sortie
</center>

Rendez-vous sur le [site d'Open AI](https://openai.com/blog/dall-e/) pour jouer avec les légendes ! 


<!--
## Autoencoder
Let's start with some definitions:

### Definitions

#### Input

$\vx$: is observed during both training and testing 

$\vy$: is observed during training but not testing

$\vz$: is not observed (neither during training nor during testing).


#### Output

$\vh$: is computed from the input (hidden/internal)

$\vytilde$: is computed from the hidden (predicted $\vy$, ~ means *circa*)

Confused?
Refer to the below figure to understand the use of different variables in different machine learning techniques.

<center>
<img src="{{site.baseurl}}/images/week07/07-3/def.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 2:</b> Variable definitions in different machine learning techniques
</center>
-->


## Auto-encodeur

### Définitions

#### Entrée

- $\vx$ : est observé à la fois pendant l'apprentissage et le test

- $\vy$ : est observé pendant l'apprentissage mais pas pendant le test

- $\vz$ : n'est pas observé (ni pendant l'apprentissage ni pendant le test)


#### Sortie

- $\vh$ : est calculé à partir de l'entrée (cachée/interne)

- $\vytilde$ : est calculé à partir de la cachée (prédit $\vy$, ~ signifie *circa*)  
<br>
Vous êtes confus ?  
Reportez-vous à la figure ci-dessous pour comprendre l'utilisation des différentes variables dans différentes techniques d'apprentissage automatique.

<center>
<img src="{{site.baseurl}}/images/week07/07-3/def.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 2 :</b> Définitions des variables dans les différentes techniques d'apprentissage automatique
</center>



<!--
### Introduction

These kinds of networks are used to learn the internal structure of some input and encode it in a hidden internal representation $\vh$, which expresses the input.

We already learned how to train energy-based models, let's look at the below network:

<center>
<img src="{{site.baseurl}}/images/week07/07-3/Autoencoder_Arch.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 3:</b> Autoencoder Architecture
</center>

Here instead of computing the minimization of the energy $\red{E}$ for $\vz$, we use an encoder that approximates the minimization and provides a hidden representation $\vh$ for a given $\vy$.

$$
\vh = \Enc(\vy)
$$

Then the hidden representation is convected into $\vytilde$ (Here we don't have a predictor, we have an encoder).

$$
\vytilde= \Dec (\vh)
$$

Basically, $\vh$ is the output of a squashing function $f$ of the rotation of our input/observation $\vy$. $\vytilde$ is the output of squashing function $g$ of the rotation of our hidden representation $\vh$.

$$
\vh = f(\mW{_h} \vy + \vb{_h}) \\
\vytilde = g(\mW{_y}\vh + \vb{_y})
$$

Note that, here $\vy$ and $\vytilde$ both belong to the same input space, and $\vh$ belong to $\mathbb{R}^d$ which is the internal representation. $\mW_h$ and $\mW_y$ are matrices for rotation.

$$
\vy, \vytilde \in \mathbb{R}^n \\
\vh \in \mathbb{R}^d \\
\mW_h \in \mathbb{R}^{d \times n} \\
\mW_y \in \mathbb{R}^{n \times d}
$$

This is called Autoencoder. The encoder is performing amortizing and we don't have to minimize the energy  $\red{E}$ but $\red{F}$:

$$
\red{F}(\vy) = \red{C}(\vy,\vytilde) + \red{R}(\vh)
$$
-->


### Introduction

Ces types de réseaux sont utilisés pour apprendre la structure interne d'une entrée et l'encodeur dans une représentation interne cachée $\vh$.

Nous avons déjà appris à entraîner des modèles à base d’énergie, regardons le réseau ci-dessous :

<center>
<img src="{{site.baseurl}}/images/week07/07-3/Autoencoder_Arch.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 3 :</b> Architecture de l'auto-encodeur
</center>  


Ici, au lieu de calculer la minimisation de l'énergie $\red{E}$ pour $\vz$, on utilise un encodeur qui approxime la minimisation et fournit une représentation cachée $\vh$ pour une $\vy$ donnée.

$$
\vh = \Enc(\vy)
$$

Ensuite, la représentation cachée est convertie en $\vytilde$ (ici nous n'avons pas de prédicteur, nous avons un encodeur).

$$
\vytilde= \Dec(\vh)
$$

En gros, $\vh$ est la sortie d'une fonction d'écrasement $f$ de la rotation de notre entrée/observation $\vy$.  
$\vytilde$ est la sortie de la fonction d'écrasement $g$ de la rotation de notre représentation cachée $\vh$.

$$
\vh = f(\mW{_h} \vy + \vb{_h}) \\
\vytilde = g(\mW{_y}\vh + \vb{_y})
$$

Notez qu'ici, $\vy$ et $\vytilde$ appartiennent tous deux au même espace d'entrée et $\vh$ appartiennent à $\mathbb{R}^d$ qui est la représentation interne. $\mW_h$ et $\mW_y$ sont des matrices de rotation.

$$
\vy, \vytilde \in \mathbb{R}^n \\
\vh \in \mathbb{R}^d \\
\mW_h \in \mathbb{R}^{d \times n} \\
\mW_y \in \mathbb{R}^{n \times d}
$$

C'est ce qu'on appelle un auto-encodeur. L'encodeur effectue un amortissement et nous n'avons pas à minimiser l'énergie $\red{E}$ mais $\red{F}$ :

$$
\red{F}(\vy) = \red{C}(\vy,\vytilde) + \red{R}(\vh)
$$



<!--
### Reconstruction Costs

Below are the two examples of reconstruction energies:

#### Real-Valued Input:

$$
\red{C}(\vy,\vytilde) = \Vert{\vy-\vytilde}\Vert^2 = \Vert \vy-\Dec[\Enc(\vy)] \Vert^2
$$

This is the square euclidean distance between $\vy$ and $\vytilde$.


#### Binary input

In the case of binary input, we can simply use binary cross-entropy

$$
\red{C}(\vy,\vytilde) = - \sum_{i=1}^n{\vy{_i}\log(\vytilde{_i}) + (1-\vy{_i})\log(1-\vytilde{_i})}
$$
-->


### Coûts de reconstruction

Vous trouverez ci-dessous deux exemples d'énergies de reconstruction :

#### Entrée à valeur réelle :

$$
\red{C}(\vy,\vytilde) = \Vert{\vy-\vytilde}\Vert^2 = \Vert \vy-\Dec[\Enc(\vy)] \Vert^2
$$

C'est la distance euclidienne carrée entre $\vy$ et $\vytilde$.


#### Entrée binaire

Dans le cas d'une entrée binaire, nous pouvons simplement utiliser l'entropie croisée binaire :

$$
\red{C}(\vy,\vytilde) = - \sum_{i=1}^n{\vy{_i}\log(\vytilde{_i}) + (1-\vy{_i})\log(1-\vytilde{_i})}
$$


<!--
### Loss Functionals

Average across all training samples of per sample loss function

$$
\mathcal{L}(\red{F}(\cdot),\mY) = \frac{1}{m}\sum_{j=1}^m{\ell(\red{F}(\cdot),\vy^{(j)})} \in \mathbb{R}
$$

We take the energy loss and try to push the energy down on $\vytilde$

$$
\ell_{\text{energy}}(\red{F}(\cdot),\vy) = \red{F}(\vy)
$$
-->

### Fonctions de perte

Moyenne sur tous les échantillons d'entraînement de la fonction de perte par échantillon :

$$
\mathcal{L}(\red{F}(\cdot),\mY) = \frac{1}{m}\sum_{j=1}^m{\ell(\red{F}(\cdot),\vy^{(j)})} \in \mathbb{R}
$$

Nous prenons la perte d'énergie et essayons de pousser l'énergie vers le bas sur ${vytilde$$

$$
\ell_{\text{energy}}(\red{F}(\cdot),\vy) = \red{F}(\vy)
$$


<!--
### Use-cases

The size of the hidden representation $\vh$ obtained using these networks can be both smaller and larger than the input size. 

If we choose a smaller $\vh$, the network can be used for non-linear dimensionality reduction.

In some situations it can be useful to have a larger than input $\vh$, however, in this scenario, a plain autoencoder would collapse. In other words, since we are trying to reconstruct the input, the model is prone to copying all the input features into the hidden layer and passing it as the output thus essentially behaving as an identity function. This needs to be avoided as this would imply that our model fails to learn anything.

To prevent the model from collapsing, we have to employ techniques that constrain the amount of region which can take zero or low energy values. These techniques can be some sort of regularization such as sparsity constraints, adding additional noise, or sampling.
-->

### Cas d'utilisation

La taille de la représentation cachée $\vh$ obtenue à l'aide de ces réseaux peut être aussi bien plus petite que plus grande que la taille de l'entrée. 

Si nous choisissons une $\vh$ plus petite, le réseau peut être utilisé pour la réduction non linéaire de la dimensionnalité.

Dans certaines situations, il peut être utile d'avoir un $\vh$ plus grand que l'entrée, cependant, dans ce scénario, un auto-encodeur simple s'effondrerait. 
En d'autres termes, puisque nous essayons de reconstruire l'entrée, le modèle est enclin à copier toutes les caractéristiques d'entrée dans la couche cachée et à les transmettre comme sortie. Il se comporte ainsi essentiellement comme une fonction d'identité. Il faut éviter ça car cela signifierait que notre modèle n'apprend rien.

Pour éviter que le modèle ne s'effondre, nous devons utiliser des techniques qui limitent la quantité de régions pouvant prendre des valeurs d'énergie nulles ou faibles.
Ces techniques peuvent être une sorte de régularisation telle que des contraintes d'éparsité, l'ajout de bruit supplémentaire ou l'échantillonnage.


<!--
### Denoising autoencoder

We add some augmentation/corruption like Gaussian noise to an input sampled from the training manifold $\vyhat$ before feeding it into the model and expect the reconstructed input $\vytilde$ to be similar to the original input $\vy$.

<center>
<img src="{{site.baseurl}}/images/week07/07-3/DenoisingAutoEncoder.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 4:</b> Denoising Autoencoder Network architecture.
</center>

An important note: The noise added to the original input should be similar to what we expect in reality, so the model can easily recover from it.

<center>
<img src="{{site.baseurl}}/images/week07/07-3/DAEOutput.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 5:</b> Measuring the traveling distance of the input data
</center>

In the image above, the light colour points on the spiral represent the original data manifold. As we add noise, we go farther from the original points. 
These noise-added points are fed into the auto-encoder to generate this graph. 
The direction of each arrow points to the original datapoint the model pushes the noise-added point towards; whereas the size of the arrow shows by how much. 
We also see a dark purple spiral region which exists because the points in this region are equidistant from two points on the data manifold. 
-->


### Auto-encodeur débruiteur

Nous ajoutons une augmentation/corruption comme un bruit gaussien à une entrée échantillonnée à partir de la variété d'apprentissage $\vyhat$ avant de la donner au modèle.
Nous nous attendons à ce que l'entrée reconstruite $\vytilde$ soit similaire à l'entrée originale $\vy$.

<center>
<img src="{{site.baseurl}}/images/week07/07-3/DenoisingAutoEncoder.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 4 :</b> Architecture du réseau de l'auto-encodeur débruiteur
</center>
 
Une note importante : le bruit ajouté à l'entrée originale doit être similaire à ce que nous attendons dans la réalité afin que le modèle puisse facilement s'en remettre.

<center>
<img src="{{site.baseurl}}/images/week07/07-3/DAEOutput.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 5 :</b> Mesure de la distance de déplacement des données d'entrée.
</center>

Dans l'image ci-dessus, les points de couleur claire sur la spirale représentent la variété de données originale. En ajoutant du bruit, on s'éloigne des points originaux. 
Ces points avec bruit sont introduits dans l'auto-encodeur pour générer ce graphique. 
La direction de chaque flèche pointe vers le point de données original vers lequel le modèle pousse le point avec bruit, tandis que la taille de la flèche indique de combien. 
Nous voyons également une région en violet foncé en forme de spirale car les points de cette région sont équidistants de deux points sur la variété de données.

