---
lang: fr
lang-ref: ch.12-2
title: Traduction automatique à faibles ressources II
lecturer: Marc’Aurelio Ranzato
authors: Angela Teng, Joanna Jin
date: 17 May 2021
typora-root-url: 12-2
translation-date: 23 Jun 2021
translator: Loïck Bourdois
---


<!--
We start with standard machine learning algorithms can be applied in the realm of machine translation translation. Then, we take a deeper look into understanding different perspectives on this application. Our setting consists of multiple languages and multiple domains, but eventually we want to maximize translation accuracy of a certain domain in a language class.

**NLP/MT Data**
- Parallel dataset
- monolingual Data
- Multiple language pairs
- Multiple Domains

**ML Techniques**
- Supervised learning
- Semi-supervised Learning
- Multi-task/multi-modal learning
- Domain adaptatation


Taking a deeper look at the type of data we are presented with in machine translation, we can better understand how these applications can be mapped to machine learning techniques. For example, if we have a parallel dataset in the space of machine translation, then we have its equivalen in supervised learning. Second, we could have monolingual data in machine translation--this translates to semi-supervised learning within the machine elarning framework. Third, if we have multiple language paris in machine translation, we can closely compare this to multi-task learning within the ML space. And lastly, if we have multiple domains in machine translation, we can compare this to domain adaptation in machine learning. When you have many domains, you naturally also want to use different domain adaptation techniques
-->

Nous commençons par les algorithmes d'apprentissage automatique standard qui peuvent être appliqués dans le domaine de la traduction automatique. 
Ensuite, nous approfondissons la compréhension des différentes perspectives de cette application. 
Notre cadre porte en plusieurs langues et plusieurs domaines, mais finalement nous voulons maximiser la précision de la traduction d'un certain domaine dans une classe de langue.

**Données pour la traduction automatique**
- Jeu de données parallèles
- Données monolingues
- Paires de langues multiples
- Domaines multiples

Techniques **d'apprentissage automatique**
- Apprentissage supervisé
- Apprentissage semi-supervisé
- Apprentissage multi-tâches/multimodal
- Adaptation au domaine


En examinant de plus près le type de données qui nous sont présentées dans le domaine de la traduction automatique, nous pouvons mieux comprendre comment ces applications peuvent être mises en correspondance avec les techniques d'apprentissage automatique. 
Par exemple, si nous avons un jeu de données parallèles dans l'espace de la traduction automatique, nous avons son équivalent dans l'apprentissage supervisé. 
Deuxièmement, nous pourrions avoir des données monolingues en traduction automatique, ce qui se traduit par un apprentissage semi-supervisé dans le cadre de l'apprentissage automatique.
Troisièmement, si nous avons des paires multilingues dans la traduction automatique, nous pouvons comparer cela à l'apprentissage multi-tâches.
Et enfin, si nous avons plusieurs domaines en traduction automatique, nous pouvons comparer cela à l'adaptation de domaine dans l'apprentissage automatique. Lorsque vous avez plusieurs domaines, vous souhaitez naturellement utiliser différentes techniques d'adaptation.


<!--
### Case Studies : Translating from English to Nepali
Let's start with a simple case study within the realm of supervsied learning. For example, let's say that we have a sentence in English and we want to trasnslate it to Nepali. This is similar to multitask learning in the sense that you have one task, and then you add another task you're interested in. Since we have multiple domains we can start thinking about domain adaptation techniques and analyzing which domain adaptation techniques are applicable to machine translation.

We can define our supervised learning method as the following when translating from English to Nepali:

$$\mathcal{D}=\left\{\left(\vx, \vy\right)_{i}\right\}_{i=1, \ldots, N}$$

Our per-sample loss using the usual attention-based transformer is defined as the following:

$$\mathcal{L}(\vtheta)=-\log p(\vy \mid \vx ; \vtheta)$$

We can regularize the model using:
- Dropout
- Label Smoothing

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure2_1.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 1:</b> Supervised Learning from English to Nepali
</center>

Beginning with a supervised learning setting, we can use the aforementioned example of translation. Our dataset is

$$D = \{(\vx,\vy)_i\}_{i=1, \vect{...}, N}$$

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure2_2.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 2:</b> Supervised Learning Visualization
</center>

We can train this model using maximum likelihood, where we want to maximize $\{ \vy\vert \vx \} $.

One way to represent this methodology is by the diagram, where you have a blue encoder that processes English sentences, and a red decoder that processes Nepali. From here, we want to compute our cross-entropy loss and update our model parameters. We may also want to regularize the model using either dropout or label smoothing. Additionally, we may need to regularize using the log loss

$$-\log p(\vy\mid \vx; \vtheta )$$

*Note: Transliteration is not word per word translation. It means that you're using the charaters from one language to make a logical translation of the word in a different language.*
-->

### Études de cas : traduction de l'anglais au népalais

Commençons par une étude de cas simple dans le domaine de l'apprentissage supervisé. 
Par exemple, disons que nous avons une phrase en anglais et que nous voulons la traduire en népalais. 
Ceci est similaire à l'apprentissage multitâche dans le sens où nous avons une tâche, puis nous ajoutons une autre tâche qui vous intéresse. 
Puisque nous avons plusieurs domaines, nous pouvons commencer à réfléchir aux techniques d'adaptation au domaine et analyser quelles techniques d'adaptation au domaine sont applicables à la traduction automatique.

Nous pouvons définir notre méthode d'apprentissage supervisé comme suit lors de la traduction de l'anglais au népalais :

$$\mathcal{D}=\left\{\left(\vx, \vy\right)_{i}\right\}_{i=1, \ldots, N}$$

Notre perte par échantillon, en utilisant le *transformer* habituel basé sur l'attention, est définie comme suit :

$$\mathcal{L}(\vtheta)=-\log p(\vy \mid \vx ; \vtheta)$$

Nous pouvons régulariser le modèle en utilisant :
- le *dropout*
- le lissage d'étiquette

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure2_1.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 1 :</b> Apprentissage supervisé de l'anglais au népalais
</center>

En commençant par le cadre d'apprentissage supervisé, nous pouvons utiliser l'exemple de traduction mentionné plus haut. Notre jeu de données est :

$$D = \{(\vx,\vy)_i\}_{i=1, \vect{...}, N}$$

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure2_2.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 2 :</b> Visualisation de l'apprentissage supervisé
</center>

Nous pouvons entraîner ce modèle en utilisant le maximum de vraisemblance où nous voulons maximiser $\{ \vy\vert \vx \} $.

Une façon de représenter cette méthodologie est via un diagramme où nous avons un encodeur bleu qui traite les phrases anglaises et un décodeur rouge qui traite le népalais.
À partir de là, nous voulons calculer notre perte d'entropie croisée et mettre à jour les paramètres de notre modèle. 
Nous pouvons également vouloir régulariser le modèle en utilisant le *dropout* ou le lissage d'étiquettes. 
En outre, nous pouvons avoir besoin de régulariser en utilisant la perte logarithmique :

$$-\log p(\vy\mid \vx ; \vtheta )$$

Remarque : la translittération n'est pas une traduction mot à mot. Cela signifie que vous utilisez les caractères d'une langue pour traduire logiquement le mot dans une autre langue.



<!--
### How can we improve generalization?

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure3_1.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 3:</b> Semi-Supervised Learning (DAE) from English to Nepali
</center>

We can get additional source side monolingual data with this approach as well.

$$
\begin{array}{c}
\mathcal{D}=\left\{(\vx, \vy)_{i}\right\}_{i=1, \ldots, N} \\
\mathcal{M}^{s}=\left\{\vx_{j}^{s}\right\}_{j=1, \ldots, M_{s}}
\end{array}
$$

When using the DAE learning framework, we an either pre-train or add a DAE loss to the supervised cross entropy term:

$$
\mathcal{L}^\text{DAE}(\vtheta)=-\log p(\vx \mid \vx+\vect{n})
$$

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure3_2.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 4:</b> Semi-Supervised Learning (DAE) Diagram
</center>

One way to leverage an additional dataset is by trying to model $p(\vx)$ with a semi-supervised approach. One way to model $$p(\vx)$$ is via the denoising of an auto-encoder. This is particularly useful because the encoder and decoder share a similar machine translation methodology. In the semi-supervised learning approach, going from English to Nepali, we have:

$$\mathcal{D} =\lbrace {(\vx, \vy)_{i} \rbrace }_{i=1, \vect{...}, N}$$

$$\mathcal{M}^{s}=\left\{\vx_{j}^{s}\right\}_{j=1, \vect{...}, M_{s}}$$

And when we want to predict missing labels using decoding and training noise, we can use cross-entropy loss as such:

$$\mathcal{L}^\text{ST}(\vtheta)=-\log p(\bar{\vy} \mid \vx+n)$$

$$\mathcal{L}(\vtheta)=\mathcal{L}^{\sup }(\vtheta)+\lambda \mathcal{L}^\text{ST}(\vtheta)$$

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure4_3.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 5:</b> Semi-Supervised Learning (ST)
</center>

Another approach would be via self-training or pseudolearning. This is an algorithm from the 90s and the idea is that you take your sentence from the monolingual dataset and then you inject noise to it, you encode the poor translation you made and then make a prediction to produce the desired outcome. You can tune the parameters by minimizing the standard cross entropy loss on the labeled data. In other words, we are minimizing $L^{\sup} (\vtheta) + \lambda L^\text{ST} \vtheta$. We are basically using a stale version of our model to produce the desired output $\vy$.

Algorithm :

- train model $p(\vy \mid \vx)$ on $\red{D}$
- repeat
  - decode $\vx^s \sim \mathcal{M}^s$ to $\bar{\vy}$ and create additional dataset
  $$\mathcal{A}^s = \{(\vx^s_j,\vy_j\}_{j=1,\vect{...},M_s})$$
  - retrain model on: $\mathcal{D} \cup \mathcal{A}^s$


This method works because:
    (1) when we produce $\vy$, we typically trying to learn the search procedure
    (2) we insert noise which creates smoothing for the output space
-->

## Comment améliorer la généralisation ?

### Approche semisupervisée

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure3_1.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 3 :</b> Apprentissage semisupervisé de l'anglais au népalais
</center>

Nous pouvons également obtenir des données monolingues supplémentaires côté source avec cette approche.

$$
\begin{array}{c}
\mathcal{D}=\left\{(\vx, \vy)_{i}\right\}_{i=1, \ldots, N} \\
\mathcal{M}^{s}=\left\{\vx_{j}^{s}\right\}_{j=1, \ldots, M_{s}}
\end{array}
$$

Lorsque nous utilisons le cadre d'apprentissage semi-supervisé, nous pouvons soit pré-entraîner, soit ajouter une perte au terme d'entropie croisée supervisé :

$$
\mathcal{L}^\text{DAE}(\vtheta)=-\log p(\vx \mid \vx+\vect{n})
$$

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure3_2.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 4 :</b> Schéma de l'apprentissage semi-supervisé
</center>

Une façon d'exploiter un jeu de données supplémentaire est d'essayer de modéliser $p(\vx)$ avec une approche semi-supervisée. 
Une façon de modéliser $$p(\vx)$$ est via un auto-encodeur débruiteur (DAE pour *denoising auto-encoder*). 
Cette méthode est particulièrement utile car l'encodeur et le décodeur partagent une méthodologie de traduction automatique similaire. 
Dans l'approche d'apprentissage semi-supervisé, en passant de l'anglais au népalais, nous avons :

$$\mathcal{D} =\lbrace {(\vx, \vy)_{i} \rbrace }_{i=1, \vect{...}, N}$$

$$\mathcal{M}^{s}=\left\{\vx_{j}^{s}\right\}_{j=1, \vect{...}, M_{s}}$$

Lorsque nous voulons prédire les étiquettes manquantes à l'aide du bruit de décodage et d'entraînement, nous pouvons utiliser la perte d'entropie croisée comme suit :

$$\mathcal{L}^\text{ST}(\vtheta)=-\log p(\bar{\vy} \mid \vx+n)$$

$$\mathcal{L}(\vtheta)=\mathcal{L}^{\sup }(\vtheta)+\lambda \mathcal{L}^\text{ST}(\vtheta)$$

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure4_3.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 5:</b> Apprentissage semi-supervisé
</center>


### Approche auto-entraînement/pseudo-apprentissage

Une autre approche serait via l'auto-entraînement ou le pseudo-apprentissage. Il s'agit d'un algorithme des années 90.
L'idée est de prendre la phrase du jeu de données monolingue, d'y injecter du bruit, puis d'encoder la mauvaise traduction effectuée. On effectue une prédiction pour produire le résultat souhaité. 
Il est possible de régler les paramètres en minimisant la perte d'entropie croisée standard sur les données étiquetées. En d'autres termes, nous minimisons $L^{\sup} (\vtheta) + \lambda L^\text{ST} \vtheta$. 
En fait, nous utilisons une version périmée de notre modèle pour produire le résultat souhaité, à savoir $\vy$.

Algorithme :
- entraînement du modèle $p(\vy \mid \vx)$ sur $\red{D}$.
- répétition de :
  - décoder $\vx^s \sim \mathcal{M}^s$ en $\bar{\vy}$ et créer un jeu de données supplémentaire
  $$\mathcal{A}^s = \{(\vx^s_j,\vy_j\}_{j=1,\vect{...},M_s})$$.
  - réentraîner le modèle sur : $\mathcal{D} \cup \mathcal{A}^s$

Cette méthode fonctionne car :
- lorsque nous produisons $\vy$, nous essayons typiquement d'apprendre la procédure de recherche
- nous insérons du bruit qui crée un lissage de l'espace de sortie

<!--
### Approach with monolingual data
If we are working on the other hand with monolingual data, first we would need to train a reverse machine learning translation system of backward machines.

Two benefits from adding target-side monolingual data
- Decoder learns a good language model
- Better generalization via data augmentation

The algorithm would stay the same as above, where we have smaller systems of encoders and decoders.

Algorithm :
- train model $p(\vx\mid \vy)$ on $\mathcal{D}$
- decode $\vy^t \sim \mathcal{M}^t$ to $\vx$ with $p(\vx\mid \vy)$, and create additional dataset $\mathcal{A}^t = \lbrace ( \bar {\vx}_k,\vy^t_k \rbrace _{k=1,\vect{...},M_t})$
- retrain model $p(\vy\mid \vx)$ on: $\mathcal{D} \cup \mathcal{A}^t$

Finally, we can put these two algorithms together in an iterative process.

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure8_1.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 6:</b> Semi-Supervised Learning Case Scenario
</center>

$$
\begin{array}{l}
\mathcal{D}=\left\{(\vx, \vy)_{i}\right\}_{i=1, \ldots, N} \\
\mathcal{M}^{t}=\left\{\vy_{k}^{t}\right\}_{k=1, \ldots, M_{t}} \\
\mathcal{M}^{s}=\left\{\vx_{j}^{s}\right\}_{j=1, \ldots, M_{s}}
\end{array}
$$

We can get additional source and target side monolingual data.

The process we can follow is via this algorithm:
- train model $p(\vx \mid \vy)$ and $p(\vy \mid \vx)$ on $\mathcal{D}$
- repeat
  - *Phase 1*
  - decode $\vy^{t} \sim \mathcal{M}^{t}$ to $\bar{\vx}$ with $p(\vx \mid \vy)$, create additional dataset

  $$\mathcal{A}^{t}=\left\{\left(\bar{\vx}_{k}, \vy_{k}^{t}\right)\right\}_{k=1, \ldots, M_{t}}$$

  - decode $\vx^{s} \sim \mathcal{M}^{s}$ to $\bar{\vy}$ with $p(\vy \mid \vx)$, create additional dataset

  $$\mathcal{A}^{s}=\left\{\left(\vx_{j}^{s}, \bar{\vy}_{j}\right)\right\}_{j=1, \ldots, M}$$

  - *Phase 2*
  - retrain both $p(\vy \mid \vx)$ and $p(\vx \mid \vy)$ on: $$\mathcal{D} \cup \mathcal{A}^{t} \cup \mathcal{A}^{s}$$

  $$
  \mathcal{L}^{\text {total }}(\vtheta)=-\log p(\vy \mid \vx)-\lambda_{1} \log p\left(\vy^{t} \mid \bar{\vx}^{t}\right)-\lambda_{2} \log p\left(\bar{\vy}^{s} \mid \vx^{s}\right)
  $$


<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure8_2.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 7:</b> Semi-Supervised Learning Diagram (ST+BT)
</center>
-->

### Approche avec des données monolingues

Si nous travaillons d'autre part avec des données monolingues, nous devons d'abord entraîner un système de rétrotraduction automatique.

L'ajout de données monolingues côté cible présente deux avantages :
- le décodeur apprend un bon modèle de langage
- il y a une meilleure généralisation grâce à l'augmentation de données


L'algorithme reste le même que ci-dessus, avec des systèmes d'encodeurs et de décodeurs plus petits :

Algorithme :
- on entraîne le modèle $p(\vx\mid \vy)$ sur $\mathcal{D}$.
- on décode $\vy^t \sim \mathcal{M}^t$ en $\vx$ avec $p(\vx\mid \vy)$ et on crée un jeu de données supplémentaire $\mathcal{A}^t = \lbrace ( \bar {\vx}_k,\vy^t_k \rbrace _{k=1,\vect{...},M_t})$
- on ré-entraîne le modèle $p(\vy\mid \vx)$ sur : $\mathcal{D} \cup \mathcal{A}^t$.

Enfin, nous pouvons mettre ces deux algorithmes ensemble dans un processus itératif.

<center>
<img src= "{{site.baseurl}}/images/week12/12-2/figure8_1.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 6 :</b> Scénario de cas d'apprentissage semi-supervisé
</center>

$$
\begin{array}{l}
\mathcal{D}=\left\{(\vx, \vy)_{i}\right\}_{i=1, \ldots, N} \\
\mathcal{M}^{t}=\left\{\vy_{k}^{t}\right\}_{k=1, \ldots, M_{t}} \\
\mathcal{M}^{s}=\left\{\vx_{j}^{s}\right\}_{j=1, \ldots, M_{s}}
\end{array}
$$

Nous pouvons obtenir des données monolingues supplémentaires du côté source et du côté cible.

Le processus que nous pouvons suivre est via cet algorithme :
- on entraîne le modèle $p(\vx \mid \vy)$ et $p(\vy \mid \vx)$ sur $\mathcal{D}$.
- on répète
  - *Phase 1*
  - décoder $\vy^{t} \sim \mathcal{M}^{t}$ en $\bar{\vx}$ avec $p(\vx \mid \vy)$, créer un jeu de données supplémentaire

  $$\mathcal{A}^{t}=\left\{\left(\bar{\vx}_{k}, \vy_{k}^{t}\right)\right\}_{k=1, \ldots, M_{t}}$$

  - décoder $\vx^{s} \sim \mathcal{M}^{s}$ en $\bar{\vy}$ avec $p(\vy \mid \vx)$, créer un jeu de données supplémentaire

  $$\mathcal{A}^{s}=\left\{\left(\vx_{j}^{s}, \bar{\vy}_{j}\right)\right\}_{j=1, \ldots, M}$$

  - *Phase 2*
  - on ré-entraîne à la fois $p(\vy \mid \vx)$ et $p(\vx \mid \vy)$ sur : $$\mathcal{D} \cup \mathcal{A}^{t} \cup \mathcal{A}^{s}$$

  $$
  \mathcal{L}^{\text {total }}(\vtheta)=-\log p(\vy \mid \vx)-\lambda_{1} \log p\left(\vy^{t} \mid \bar{\vx}^{t}\right)-\lambda_{2} \log p\left(\bar{\vy}^{s} \mid \vx^{s}\right)
  $$


<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure8_2.png" style="background-color:#DCDC ;" /><br>
<b>Figure 7 :</b> Diagramme d'apprentissage semi-supervisé
</center>


<!--
#### Deal with multiple languages

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure9.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 8:</b> Semi-Supervised Learning Case Scenario on Multiple Languages
</center>

This is the learning framework for multilingul training, which shares encoder and decoder across all the language pairs, prepends a target language identifier to the source sentence to inform decoder of desired language and concatenates all the datasets together.

Mathematically, the train uses standard cross-entropy loss:


$$\mathcal{L} (\vtheta )=-\sum_{s,t} \mathbb{E}_{( \vx,\vy )} \sim\mathcal{D}[\log p(\vy \mid \vx,t)]$$

#### How do we deal with domain adaptation?

If you have small data in domain validation, what you can do is fine-tuning, which is super effective. Basically train on domain A and finetune on domain B by continuing training for a little bit on the validation set.
-->

#### Comment traiter plusieurs langues ?

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure9.png" style="background-color:#DCDCDC ;" /><br>
<b>Figure 8 :</b> Scénario de cas d'apprentissage semi-supervisé sur plusieurs langues
</center>

Voici le cadre d'apprentissage pour l'entraînement multilingue qui partage l'encodeur et le décodeur à travers toutes les paires de langues.
On prépointe un identifiant de la langue cible à la phrase source pour informer le décodeur de la langue désirée et qui concatène tous les ensembles de données ensemble.

Mathématiquement, l'entraînement utilise la perte standard d'entropie croisée :

$$\mathcal{L} (\vtheta )=-\sum_{s,t} \mathbb{E}_{( \vx,\vy )} \sim\mathcal{D}[\log p(\vy \mid \vx,t)]$$

#### Comment traiter l'adaptation de domaine ?

Si nous avons de petites données dans la validation de domaine, nous pouvons *finetuner*.  En gros, on entraîne sur le domaine A et on *finetune* sur le domaine B en poursuivant l'entraînement pendant un petit moment sur l'ensemble de validation.


<!--
## Unsupervised MT
Let's consider English and French.

$$
\begin{array}{l}
\mathcal{M}^{t}=\left\{\vy_{k}^{t}\right\}_{k=1, . ., M_{t}} \\
\mathcal{M}^{s}=\left\{\vx_{j}^{s}\right\}_{j=1, . ., M_{s}}
\end{array}
$$

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure10_1.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 9:</b> Unsupervised Machine Translation on English and French
</center>
-->

## Traduction non supervisée
Considérons l'anglais et le français.

$$
\begin{array}{l}
\mathcal{M}^{t}=\left\{\vy_{k}^{t}\right\}_{k=1, . ., M_{t}} \\
\mathcal{M}^{s}=\left\{\vx_{j}^{s}\right\}_{j=1, . ., M_{s}}
\end{array}
$$

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure10_1.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 9 :</b> Traduction automatique non supervisée sur l'anglais et le français
</center>

<!--
### Iterative BT
 The following architecture first translate French to some random unknown English words. Since there is no ground truth reference, what could do is feeding this translation to another machine translation system goes from English to French. The problem here is lack of constrains on $\bar{\vx}$

 <center>
 <img src="{{site.baseurl}}/images/week12/12-2/figure11.png" style="background-color:#DCDCDC;" /><br>
 <b> Figure 10:</b> Iterative BT for English and French
 </center>
-->

### Rétrotraduction itérative

L'architecture suivante traduit d'abord le français en quelques mots anglais inconnus et aléatoires. 
Puisqu'il n'y a pas de référence de base, ce qui peut être fait est de donner cette traduction à un autre système de traduction automatique allant de l'anglais au français.
Le problème ici est le manque de contraintes sur $\bar{\vx}$.

 <center>
 <img src="{{site.baseurl}}/images/week12/12-2/figure11.png" style="background-color:#DCDCDC" /><br>
 <b>Figure 10 :</b> Rétrotraduction itérative pour l'anglais et le français
 </center>


<!--
### DAE
DAE adds a constraint on the $\bar{\vect{x}}$ to make sure that decoder outputs fluently in the desired language. One way is adding denoising of the encoding turn to the loss function. This may not work since decoder may behave differently when fed with representations from French encoder vs English encoder (lack of modularity)

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure12.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 11:</b> DAE
</center>
-->

### Auto-encodeur débruiteur (DAE)
Le DAE ajoute une contrainte sur $\bar{\vect{x}}$ pour s'assurer que le décodeur produit couramment dans la langue désirée. 
Une façon de faire est d'ajouter le débruitage d'encodage à la fonction de perte. 
Cela peut ne pas fonctionner car le décodeur peut se comporter différemment lorsqu'on lui donne des représentations provenant d'un encodeur français par rapport à un encodeur anglais (manque de modularité).

<center>
<img src= "{{site.baseurl}}/images/week12/12-2/figure12.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 11 :</b> Auto-encodeur débruiteur (DAE)
</center>

<!--
### Multi-Lingual
One way to fix is by sharing all parameters of encoder and deconder so that the feature space share no matter whether you feed the French or English sentence (only one encoder and decoder now)

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure13.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 12:</b> Multi-Lingual
</center>
-->

### Approche multilingue
Une façon de résoudre le problème est de partager tous les paramètres de l'encodeur et du décodeur afin que l'espace des caractéristiques soit partagé, peu importe si on donne une phrase en français ou en anglais (un seul encodeur et décodeur maintenant).

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure13.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 12 :</b> Approche multilingue
</center>

<!--
### BLEU score

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure14.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 13:</b> BLEU Score
</center>

This graph tells why machine translation is very large scale learning, because you need to compensate for the lack of direct supervision by adding more and more data.
-->

### Score BLEU

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure14.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 13 :</b> Score BLEU
</center>

Ce graphique explique pourquoi la traduction automatique est un apprentissage à très grande échelle. Il faut compenser le manque de supervision directe en ajoutant de plus en plus de données.


<!--
### FLoRes Ne-En

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure15.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 14:</b> FLoRes Ne-En
</center>

#### Results on FLoRes: Ne-En
<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure16.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 15:</b> FLoRes Ne-En Results
</center>

The unsupervised learning doesn't work at all in this case because two monolingual for the stats are from different domains and there is no way to find corresponences.

If adding English-Hindi data since Hindi and Nepali are similar, all four models dramatically improve (Red).

If you want to add language that is less related, you need to add so much. Since low-resource MT requires big data and big compute!

In conclusion, the less labeled data you have, the more data you need to use:

Supervised Learning
- Each datum yields X bits of information useful to solve the task
- Need N samples
- Need model of size YB.

Unsupervised Learning
- Each datum yields X/1000 bits
- Need N*1000 samples
- Need model of size Y*f(1000) MB.
-->

### FLoRes Ne-En

<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure15.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 14 :</b> FLoRes Ne-En
</center>

#### Résultats
<center>
<img src= "{{site.baseurl}}/images/week12/12-2/figure16.png" style="background-color:#DCDCDC;" /><br>
<b>Figure 15 :</b> Résultats de FLoRes Ne-En
</center>

L'apprentissage non supervisé ne fonctionne pas du tout dans ce cas car deux monolingues sont issus de domaines différents et il n'y a aucun moyen de trouver des corresponances.

Si l'on ajoute des données en anglais et en hindi, puisque l'hindi et le népalais sont similaires, les quatre modèles s'améliorent considérablement (en rouge).

Si nous voulons ajouter une langue qui est moins apparentée, nous devons en ajouter autant. La traduction automatique à faibles ressources nécessite de grandes données et de grands calculs !

En conclusion, moins vous avez de données étiquetées, plus vous devez utiliser de données :

L'apprentissage supervisé :
- Chaque donnée fournit $X$ bits d'information utiles pour résoudre la tâche
- Besoin de $N$ échantillons
- Besoin d'un modèle de taille $Y$B

Apprentissage non supervisé :
- Chaque donnée fournit $X$/$1000$ bits
- Besoin de $N \times 1000$ échantillons
- Besoin d'un modèle de taille $Y \times f(1000)$ MB


<!--
### Perspectives
Typically, in machine learning and machine translation, we always consider a domain mismatch between the training and the test distribution.
 When we have a slightly different domain, we need to do domain adaptation (e.g. domain tagging and finetuning). Here we will talk about a different domain mismach which is:

#### Source-Target Domain Mismatch
<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure18.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 16:</b> Source-Target Domain Mismatch in a Given Language
</center>

#### How to quantify STDM?
<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure19.png" style="background-color:#DCDCDC;" /><br>
<b> Figure 17:</b> Quantifying STDM
</center>

#### In conclusion:
* STDM: a new kind of domain mismatch, intrinsic to the MT task.
* STDM is particularly significant in low resource language pairs.
* Metric & controlled setting enable study and better understanding of STDM.
* Methods that leverage source side monolingual data are more robust to STDM.
* In practice, the influence of STDM depends on several factors, such as the amount of
parallel and monolingual data, the domains, language pair, etc. In particular, if domains
are not too distinct, STDM may even help regularizing!
-->

### Perspectives
En général, dans le domaine de l'apprentissage automatique et de la traduction automatique, nous considérons un décalage de domaine entre la distribution d'entraînement et la distribution de test. 
Lorsque nous avons un domaine légèrement différent, nous devons procéder à une adaptation au domaine (par exemple, l'étiquetage du dommaine ou le *finetuning*).


#### Inadéquation de domaine entre la source et la cible (STDM pour *Source-Target Domain Mismatch*)
<center>
<img src= "{{site.baseurl}}/images/week12/12-2/figure18.png" style="background-color:#DCDCDC ;" /><br>
<b>Figure 16 :</b> inadéquation entre le domaine source et le domaine cible dans une langue donnée
</center>

#### Comment quantifier l'inadéquation ?
<center>
<img src="{{site.baseurl}}/images/week12/12-2/figure19.png" style="background-color:#DCDCDC ;" /><br>
<b>Figure 17 :</b> Quantification de l'inadéquation
</center>

#### En conclusion :
* Inadéquation de domaine entre la source et la cible : un nouveau type de décalage de domaine, intrinsèque à la tâche de traduction automatique.
* L'inadéquation de domaines est particulièrement significative dans les paires de langues à faibles ressources.
* La métrique et le cadre contrôlé permettent d'étudier et de mieux comprendre l'inadéquation de domaines.
* Les méthodes qui exploitent les données monolingues du côté source sont plus robustes à l'inadéquation de domaines.
* En pratique, l'influence de l'inadéquation dépend de plusieurs facteurs, tels que la quantité de données parallèles et monolingues, les domaines, la paire de langues, etc. En particulier, si les domaines ne sont pas trop distincts, l'inadéquation de domains peut même aider à régulariser !
